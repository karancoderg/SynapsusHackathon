{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# EMG Signal Classification Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {
    "id": "imports-header"
   },
   "source": [
    "## Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, mixed_precision, callbacks\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from scipy.stats import mode\n",
    "from scipy.signal import butter, filtfilt, iirnotch\n",
    "import warnings\n",
    "import gc\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {
    "id": "config-header"
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {
    "id": "config"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'\n",
    "ARTIFACTS_DIR = 'artifacts_final'\n",
    "FS = 512\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 128\n",
    "RANDOM_SEED = 42\n",
    "VAL_FILE_RATIO = 0.50\n",
    "WINDOW_MS = 400\n",
    "STRIDE_MS = 160\n",
    "L2_REG = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gpu-header",
   "metadata": {
    "id": "gpu-header"
   },
   "source": [
    "## GPU Setup and Random Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gpu-setup",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gpu-setup",
    "outputId": "1c209896-d94f-4a7f-a8e1-28cf0f0e6a1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed Precision (FP16) Enabled\n"
     ]
    }
   ],
   "source": [
    "# GPU Setup\n",
    "try:\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        policy = mixed_precision.Policy('mixed_float16')\n",
    "        mixed_precision.set_global_policy(policy)\n",
    "        print(\"Mixed Precision (FP16) Enabled\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# random seeds for reproducibility\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocessing-header",
   "metadata": {
    "id": "preprocessing-header"
   },
   "source": [
    "## Signal Preprocessing Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preprocessing",
   "metadata": {
    "id": "preprocessing"
   },
   "outputs": [],
   "source": [
    "class SignalPreprocessor:\n",
    "    \"\"\"Standard Preprocessing Pipeline for EMG signals\"\"\"\n",
    "    def __init__(self, fs=1000, bandpass_low=20.0, bandpass_high=450.0, notch_freq=50.0):\n",
    "        self.fs = fs\n",
    "        nyq = fs / 2\n",
    "        low = max(0.001, min(bandpass_low / nyq, 0.99))\n",
    "        high = max(low + 0.01, min(bandpass_high / nyq, 0.999))\n",
    "        self.b_bp, self.a_bp = butter(4, [low, high], btype='band')\n",
    "        self.b_notch, self.a_notch = iirnotch(notch_freq, 30.0, self.fs) if notch_freq > 0 else (None, None)\n",
    "        self.channel_means, self.channel_stds = None, None\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, signals_list):\n",
    "        all_signals = np.concatenate(signals_list, axis=0)\n",
    "        self.channel_means = np.mean(all_signals, axis=0)\n",
    "        self.channel_stds = np.std(all_signals, axis=0) + 1e-8\n",
    "        self.fitted = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, signal):\n",
    "        if len(signal) > 12:\n",
    "            signal = filtfilt(self.b_bp, self.a_bp, signal, axis=0)\n",
    "            if self.b_notch is not None:\n",
    "                signal = filtfilt(self.b_notch, self.a_notch, signal, axis=0)\n",
    "        if self.fitted:\n",
    "            return (signal - self.channel_means) / self.channel_stds\n",
    "        return (signal - np.mean(signal, axis=0)) / (np.std(signal, axis=0) + 1e-8)\n",
    "\n",
    "    def segment(self, signal, window_ms=200, stride_ms=100):\n",
    "        win_sz = int(window_ms * self.fs / 1000)\n",
    "        step = int(stride_ms * self.fs / 1000)\n",
    "        n = len(signal)\n",
    "        if n < win_sz: return None\n",
    "        n_win = (n - win_sz) // step + 1\n",
    "        idx = np.arange(win_sz)[None, :] + np.arange(n_win)[:, None] * step\n",
    "        return signal[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "augmentation-header",
   "metadata": {
    "id": "augmentation-header"
   },
   "source": [
    "## Data Augmentation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "augmentation",
   "metadata": {
    "id": "augmentation"
   },
   "outputs": [],
   "source": [
    "def augment_dataset_advanced(X, y):\n",
    "    # Advanced data augmentation with channel masking and mixup\n",
    "    print(f\" Augmenting Data (Input: {len(X)} windows)...\")\n",
    "    b, t, c = X.shape\n",
    "\n",
    "    # Channel Masking\n",
    "    X_mask = X.copy()\n",
    "    mask_indices = np.random.choice(b, size=int(b * 0.5), replace=False)\n",
    "    for i in mask_indices:\n",
    "        ch = np.random.randint(0, c)\n",
    "        X_mask[i, :, ch] = 0\n",
    "    X_mask = X_mask + np.random.normal(0, 0.02, size=X_mask.shape)\n",
    "\n",
    "    # MixUp\n",
    "    indices = np.random.permutation(b)\n",
    "    X_shuffled = X[indices]\n",
    "    alpha = 0.2\n",
    "    lam = np.random.beta(alpha, alpha, size=(b, 1, 1))\n",
    "    X_mix = lam * X + (1 - lam) * X_shuffled\n",
    "    y_mix = y.copy()\n",
    "\n",
    "    X_final = np.concatenate([X, X_mask, X_mix], axis=0)\n",
    "    y_final = np.concatenate([y, y, y_mix], axis=0)\n",
    "    print(f\" Augmentation complete. Size: {len(X_final)} (3x)\")\n",
    "    return X_final, y_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-utils-header",
   "metadata": {
    "id": "data-utils-header"
   },
   "source": [
    "## Data Loading Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-utils",
   "metadata": {
    "id": "data-utils"
   },
   "outputs": [],
   "source": [
    "def get_session_files(data_dir, sessions):\n",
    "    files = []\n",
    "    for session in sessions:\n",
    "        pattern = f'{data_dir}/**/{session}/**/*.csv'\n",
    "        files.extend(sorted(glob.glob(pattern, recursive=True)))\n",
    "    return files\n",
    "\n",
    "def split_files_by_ratio(files, val_ratio, seed=RANDOM_SEED):\n",
    "    \"\"\"Split files by gesture type maintaining ratio\"\"\"\n",
    "    gesture_files = {}\n",
    "    for f in files:\n",
    "        match = re.search(r'gesture(\\d+)', f)\n",
    "        if match:\n",
    "            g = int(match.group(1))\n",
    "            gesture_files.setdefault(g, []).append(f)\n",
    "    train, val = [], []\n",
    "    rng = random.Random(seed)\n",
    "    for g, gfiles in gesture_files.items():\n",
    "        rng.shuffle(gfiles)\n",
    "        n_val = max(1, int(len(gfiles) * val_ratio))\n",
    "        val.extend(gfiles[:n_val])\n",
    "        train.extend(gfiles[n_val:])\n",
    "    return train, val\n",
    "\n",
    "def load_files_data(file_list):\n",
    "    data_list, labels_list = [], []\n",
    "    for f in file_list:\n",
    "        try:\n",
    "            lbl = int(re.search(r'gesture(\\d+)', f).group(1))\n",
    "            d = pd.read_csv(f).values\n",
    "            if d.shape[1] >= 8:\n",
    "                data_list.append(d)\n",
    "                labels_list.append(np.full(len(d), lbl))\n",
    "        except: pass\n",
    "    return data_list, labels_list\n",
    "\n",
    "def window_data(data_list, labels_list, prep, window_ms, stride_ms):\n",
    "    \"\"\"windowed data from continuous signals\"\"\"\n",
    "    X_wins, y_wins = [], []\n",
    "    win_sz = int(window_ms * FS / 1000)\n",
    "    step = int(stride_ms * FS / 1000)\n",
    "    for d, l in zip(data_list, labels_list):\n",
    "        d_filt = prep.transform(d)\n",
    "        w = prep.segment(d_filt, window_ms, stride_ms)\n",
    "        if w is not None:\n",
    "            X_wins.append(w)\n",
    "            n_win = (len(d) - win_sz) // step + 1\n",
    "            idx = np.arange(win_sz)[None, :] + np.arange(n_win)[:, None] * step\n",
    "            w_modes = mode(l[idx], axis=1, keepdims=True)[0].flatten()\n",
    "            y_wins.append(w_modes)\n",
    "    if not X_wins: return None, None\n",
    "    return np.concatenate(X_wins), np.concatenate(y_wins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "models-header",
   "metadata": {
    "id": "models-header"
   },
   "source": [
    "## Model Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inception-header",
   "metadata": {
    "id": "inception-header"
   },
   "source": [
    "### -> Inception-SE-TCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inception-model",
   "metadata": {
    "id": "inception-model"
   },
   "outputs": [],
   "source": [
    "def squeeze_excite_block(input_tensor, ratio=8):\n",
    "    \"\"\"Squeeze and Excitation block for attention\"\"\"\n",
    "    filters = input_tensor.shape[-1]\n",
    "    se = layers.GlobalAveragePooling1D()(input_tensor)\n",
    "    se = layers.Dense(filters // ratio, activation='relu', kernel_regularizer=l2(L2_REG))(se)\n",
    "    se = layers.Dense(filters, activation='sigmoid', kernel_regularizer=l2(L2_REG))(se)\n",
    "    se = layers.Reshape((1, filters))(se)\n",
    "    return layers.Multiply()([input_tensor, se])\n",
    "\n",
    "def inception_block(x, filters, dilation_rate):\n",
    "    \"\"\"Inception block with different kernel sizes\"\"\"\n",
    "    b1 = layers.Conv1D(filters//2, 3, dilation_rate=dilation_rate, padding='same', kernel_regularizer=l2(L2_REG))(x)\n",
    "    b1 = layers.BatchNormalization()(b1)\n",
    "    b1 = layers.Activation('relu')(b1)\n",
    "    b2 = layers.Conv1D(filters//2, 7, dilation_rate=dilation_rate, padding='same', kernel_regularizer=l2(L2_REG))(x)\n",
    "    b2 = layers.BatchNormalization()(b2)\n",
    "    b2 = layers.Activation('relu')(b2)\n",
    "    return layers.Concatenate()([b1, b2])\n",
    "\n",
    "def make_inception_se_tcn(input_shape, n_classes):\n",
    "    \"\"\"Inception-SE-TCN model with attention\"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.GaussianNoise(0.05)(inputs)\n",
    "    filters = 64\n",
    "    for dilation_rate in [1, 2, 4, 8]:\n",
    "        prev_x = x\n",
    "        x = inception_block(x, filters, dilation_rate)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        x = squeeze_excite_block(x, ratio=8)\n",
    "        if prev_x.shape[-1] != filters:\n",
    "            prev_x = layers.Conv1D(filters=filters, kernel_size=1, padding='same')(prev_x)\n",
    "        x = layers.Add()([x, prev_x])\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    x = layers.MultiHeadAttention(key_dim=64, num_heads=4, dropout=0.3)(x, x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dense(64, activation='relu', kernel_regularizer=l2(L2_REG))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(n_classes, activation='softmax', dtype='float32')(x)\n",
    "    return keras.Model(inputs, outputs, name='Inception_SE_Attn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "semg-header",
   "metadata": {
    "id": "semg-header"
   },
   "source": [
    "### -> sEMG Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "semg-model",
   "metadata": {
    "id": "semg-model"
   },
   "outputs": [],
   "source": [
    "def conv_block(x, filters, kernel_size, pool=True):\n",
    "    \"\"\"Convolutional block with batch norm and dropout\"\"\"\n",
    "    x = layers.Conv1D(filters, kernel_size, padding='same', kernel_regularizer=l2(L2_REG))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    if pool: x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    return x\n",
    "\n",
    "def make_semg_net(input_shape, n_classes):\n",
    "    \"\"\"sEMG Net model\"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.GaussianNoise(0.05)(inputs)\n",
    "    x = conv_block(x, 64, 9, pool=False)\n",
    "    x = conv_block(x, 128, 5, pool=True)\n",
    "    x = conv_block(x, 256, 3, pool=True)\n",
    "    x = conv_block(x, 512, 3, pool=True)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dense(512, activation='relu', kernel_regularizer=l2(L2_REG))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(n_classes, activation='softmax', dtype='float32')(x)\n",
    "    return keras.Model(inputs, outputs, name='sEMG_Net')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-header",
   "metadata": {
    "id": "training-header"
   },
   "source": [
    "## Training Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training",
   "metadata": {
    "id": "training"
   },
   "outputs": [],
   "source": [
    "def train_and_save(model_builder, model_name, X_train, y_train_hot, X_val, y_val_hot, input_shape, n_classes, class_weights):\n",
    "    print(f\"\\n TRAIN: {model_name} (Weighted)\")\n",
    "\n",
    "    total_steps = len(X_train) // BATCH_SIZE * EPOCHS\n",
    "    lr_schedule = tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
    "        initial_learning_rate=0.001, first_decay_steps=int(total_steps * 0.3),\n",
    "        t_mul=2.0, m_mul=0.9, alpha=1e-5\n",
    "    )\n",
    "\n",
    "    save_path = f'{ARTIFACTS_DIR}/best_{model_name}.keras'\n",
    "    checkpoint = callbacks.ModelCheckpoint(save_path, monitor='val_accuracy', mode='max', save_best_only=True, verbose=0)\n",
    "\n",
    "    model = model_builder(input_shape, n_classes)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "                  loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Applying class weights during training\n",
    "    model.fit(X_train, y_train_hot,\n",
    "              validation_data=(X_val, y_val_hot),\n",
    "              epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "              callbacks=[checkpoint],\n",
    "              class_weight=class_weights,\n",
    "              verbose=1)\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "main-header",
   "metadata": {
    "id": "main-header"
   },
   "source": [
    "## Main Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main-pipeline",
   "metadata": {
    "id": "main-pipeline"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main training pipeline\"\"\"\n",
    "    os.makedirs(ARTIFACTS_DIR, exist_ok=True)\n",
    "    print(\"\\n FINAL PIPELINE: 2-Model Ensemble + Class Weights\\n\")\n",
    "\n",
    "    #  Load Data\n",
    "    existing_csvs = glob.glob(f'{DATA_DIR}/**/*.csv', recursive=True)\n",
    "    if not existing_csvs:\n",
    "        import gdown, zipfile\n",
    "        gdown.download('https://drive.google.com/uc?id=16iNEwhThf2LcX7rOOVM03MTZiwq7G51x', 'dataset.zip', quiet=False)\n",
    "        with zipfile.ZipFile('dataset.zip', 'r') as z: z.extractall(DATA_DIR)\n",
    "        os.remove('dataset.zip')\n",
    "\n",
    "    train_files = get_session_files(DATA_DIR, ['Session1', 'Session2'])\n",
    "    session3_files = get_session_files(DATA_DIR, ['Session3'])\n",
    "    val_files, test_files = split_files_by_ratio(session3_files, VAL_FILE_RATIO)\n",
    "\n",
    "    train_data, train_labels = load_files_data(train_files)\n",
    "    val_data, val_labels = load_files_data(val_files)\n",
    "    test_data, test_labels = load_files_data(test_files)\n",
    "\n",
    "    # Preprocess\n",
    "    prep = SignalPreprocessor(fs=FS).fit(train_data)\n",
    "    X_train, y_train_raw = window_data(train_data, train_labels, prep, WINDOW_MS, STRIDE_MS)\n",
    "    X_val, y_val_raw = window_data(val_data, val_labels, prep, WINDOW_MS, STRIDE_MS)\n",
    "    X_test, y_test_raw = window_data(test_data, test_labels, prep, WINDOW_MS, STRIDE_MS)\n",
    "\n",
    "    # Augment\n",
    "    X_train, y_train_raw = augment_dataset_advanced(X_train, y_train_raw)\n",
    "\n",
    "    # Encode\n",
    "    le = LabelEncoder().fit(y_train_raw)\n",
    "    y_train = le.transform(y_train_raw)\n",
    "    y_val = np.array([le.transform([l])[0] if l in le.classes_ else -1 for l in y_val_raw])\n",
    "    y_test = np.array([le.transform([l])[0] if l in le.classes_ else -1 for l in y_test_raw])\n",
    "\n",
    "    n_classes = len(le.classes_)\n",
    "    input_shape = X_train.shape[1:]\n",
    "\n",
    "    y_train_hot = tf.keras.utils.to_categorical(y_train, n_classes)\n",
    "    y_val_hot = tf.keras.utils.to_categorical(y_val, n_classes)\n",
    "\n",
    "    # Define class weights\n",
    "    class_weights = {\n",
    "        0: 1.0,\n",
    "        1: 1.5,\n",
    "        2: 1.5,\n",
    "        3: 1.0,\n",
    "        4: 1.0\n",
    "    }\n",
    "    print(f\" Applying Class Weights: {class_weights}\")\n",
    "\n",
    "    return X_train, y_train_hot, X_val, y_val_hot, X_test, y_test, input_shape, n_classes, class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-execution-header",
   "metadata": {
    "id": "training-execution-header"
   },
   "source": [
    "## Model Training Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "training-execution",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "training-execution",
    "outputId": "7313a749-1cca-490a-c9d3-aa1e785e6f49"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " FINAL PIPELINE: 2-Model Ensemble + Class Weights\n",
      "\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=16iNEwhThf2LcX7rOOVM03MTZiwq7G51x\n",
      "From (redirected): https://drive.google.com/uc?id=16iNEwhThf2LcX7rOOVM03MTZiwq7G51x&confirm=t&uuid=06bf897f-4355-48a9-98ed-97c570ee4bc6\n",
      "To: /content/dataset.zip\n",
      "100%|██████████| 489M/489M [00:07<00:00, 67.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Augmenting Data (Input: 52500 windows)...\n",
      " Augmentation complete. Size: 157500 (3x)\n",
      " Applying Class Weights: {0: 1.0, 1: 1.5, 2: 1.5, 3: 1.0, 4: 1.0}\n",
      "\n",
      " TRAIN: inception_se (Weighted)\n",
      "Epoch 1/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 39ms/step - accuracy: 0.5646 - loss: 1.5151 - val_accuracy: 0.7555 - val_loss: 0.8982\n",
      "Epoch 2/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7024 - loss: 1.3100 - val_accuracy: 0.7998 - val_loss: 0.8301\n",
      "Epoch 3/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7324 - loss: 1.2584 - val_accuracy: 0.8006 - val_loss: 0.8250\n",
      "Epoch 4/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.7483 - loss: 1.2270 - val_accuracy: 0.7933 - val_loss: 0.8449\n",
      "Epoch 5/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.7606 - loss: 1.2069 - val_accuracy: 0.7650 - val_loss: 0.9089\n",
      "Epoch 6/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7704 - loss: 1.1911 - val_accuracy: 0.8011 - val_loss: 0.8273\n",
      "Epoch 7/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.7791 - loss: 1.1744 - val_accuracy: 0.7975 - val_loss: 0.8611\n",
      "Epoch 8/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.7851 - loss: 1.1624 - val_accuracy: 0.7861 - val_loss: 0.8818\n",
      "Epoch 9/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.7924 - loss: 1.1469 - val_accuracy: 0.8071 - val_loss: 0.8423\n",
      "Epoch 10/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7961 - loss: 1.1384 - val_accuracy: 0.8156 - val_loss: 0.8289\n",
      "Epoch 11/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.8002 - loss: 1.1311 - val_accuracy: 0.8201 - val_loss: 0.8150\n",
      "Epoch 12/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8054 - loss: 1.1199 - val_accuracy: 0.8182 - val_loss: 0.8221\n",
      "Epoch 13/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.8095 - loss: 1.1093 - val_accuracy: 0.8204 - val_loss: 0.8134\n",
      "Epoch 14/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.8118 - loss: 1.1034 - val_accuracy: 0.8218 - val_loss: 0.8006\n",
      "Epoch 15/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.8152 - loss: 1.0959 - val_accuracy: 0.8221 - val_loss: 0.8045\n",
      "Epoch 16/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.8168 - loss: 1.0925 - val_accuracy: 0.8251 - val_loss: 0.8017\n",
      "Epoch 17/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8179 - loss: 1.0886 - val_accuracy: 0.8211 - val_loss: 0.8091\n",
      "Epoch 18/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8185 - loss: 1.0889 - val_accuracy: 0.8095 - val_loss: 0.8249\n",
      "Epoch 19/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.7948 - loss: 1.1396 - val_accuracy: 0.7976 - val_loss: 0.8577\n",
      "Epoch 20/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.7947 - loss: 1.1393 - val_accuracy: 0.8128 - val_loss: 0.8219\n",
      "Epoch 21/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.7980 - loss: 1.1357 - val_accuracy: 0.8094 - val_loss: 0.8511\n",
      "Epoch 22/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.7994 - loss: 1.1375 - val_accuracy: 0.8085 - val_loss: 0.8479\n",
      "Epoch 23/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8000 - loss: 1.1333 - val_accuracy: 0.7911 - val_loss: 0.8897\n",
      "Epoch 24/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8010 - loss: 1.1322 - val_accuracy: 0.8073 - val_loss: 0.8388\n",
      "Epoch 25/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8042 - loss: 1.1284 - val_accuracy: 0.8068 - val_loss: 0.8548\n",
      "Epoch 26/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8055 - loss: 1.1248 - val_accuracy: 0.8044 - val_loss: 0.8520\n",
      "Epoch 27/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8078 - loss: 1.1204 - val_accuracy: 0.8108 - val_loss: 0.8450\n",
      "Epoch 28/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8087 - loss: 1.1181 - val_accuracy: 0.8141 - val_loss: 0.8416\n",
      "Epoch 29/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8110 - loss: 1.1119 - val_accuracy: 0.8149 - val_loss: 0.8357\n",
      "Epoch 30/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8126 - loss: 1.1077 - val_accuracy: 0.8203 - val_loss: 0.8163\n",
      "Epoch 31/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8141 - loss: 1.1055 - val_accuracy: 0.8166 - val_loss: 0.8367\n",
      "Epoch 32/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8169 - loss: 1.1015 - val_accuracy: 0.8172 - val_loss: 0.8285\n",
      "Epoch 33/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8158 - loss: 1.1013 - val_accuracy: 0.8245 - val_loss: 0.8092\n",
      "Epoch 34/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8188 - loss: 1.0931 - val_accuracy: 0.8220 - val_loss: 0.8092\n",
      "Epoch 35/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8205 - loss: 1.0917 - val_accuracy: 0.8209 - val_loss: 0.8189\n",
      "Epoch 36/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8221 - loss: 1.0877 - val_accuracy: 0.8283 - val_loss: 0.8139\n",
      "Epoch 37/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8232 - loss: 1.0823 - val_accuracy: 0.8246 - val_loss: 0.8131\n",
      "Epoch 38/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.8251 - loss: 1.0777 - val_accuracy: 0.8203 - val_loss: 0.8184\n",
      "Epoch 39/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8267 - loss: 1.0771 - val_accuracy: 0.8231 - val_loss: 0.8164\n",
      "Epoch 40/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8280 - loss: 1.0705 - val_accuracy: 0.8166 - val_loss: 0.8234\n",
      "Epoch 41/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.8280 - loss: 1.0687 - val_accuracy: 0.8239 - val_loss: 0.8088\n",
      "Epoch 42/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8309 - loss: 1.0655 - val_accuracy: 0.8119 - val_loss: 0.8330\n",
      "Epoch 43/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8312 - loss: 1.0613 - val_accuracy: 0.8218 - val_loss: 0.8191\n",
      "Epoch 44/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.8323 - loss: 1.0590 - val_accuracy: 0.8211 - val_loss: 0.8154\n",
      "Epoch 45/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8334 - loss: 1.0555 - val_accuracy: 0.8231 - val_loss: 0.8084\n",
      "Epoch 46/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8350 - loss: 1.0502 - val_accuracy: 0.8222 - val_loss: 0.8105\n",
      "Epoch 47/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8352 - loss: 1.0498 - val_accuracy: 0.8208 - val_loss: 0.8224\n",
      "Epoch 48/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8356 - loss: 1.0470 - val_accuracy: 0.8231 - val_loss: 0.8129\n",
      "Epoch 49/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8366 - loss: 1.0469 - val_accuracy: 0.8223 - val_loss: 0.8193\n",
      "Epoch 50/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8373 - loss: 1.0455 - val_accuracy: 0.8212 - val_loss: 0.8199\n",
      "Epoch 51/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8383 - loss: 1.0410 - val_accuracy: 0.8198 - val_loss: 0.8266\n",
      "Epoch 52/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8379 - loss: 1.0428 - val_accuracy: 0.8192 - val_loss: 0.8293\n",
      "Epoch 53/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.8386 - loss: 1.0410 - val_accuracy: 0.8177 - val_loss: 0.8320\n",
      "Epoch 54/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8388 - loss: 1.0398 - val_accuracy: 0.8000 - val_loss: 0.8662\n",
      "Epoch 55/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8180 - loss: 1.0901 - val_accuracy: 0.8037 - val_loss: 0.8455\n",
      "Epoch 56/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8176 - loss: 1.0945 - val_accuracy: 0.8045 - val_loss: 0.8565\n",
      "Epoch 57/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.8166 - loss: 1.0973 - val_accuracy: 0.8204 - val_loss: 0.8212\n",
      "Epoch 58/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8171 - loss: 1.0983 - val_accuracy: 0.8248 - val_loss: 0.8158\n",
      "Epoch 59/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8172 - loss: 1.0974 - val_accuracy: 0.8127 - val_loss: 0.8312\n",
      "Epoch 60/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8175 - loss: 1.0988 - val_accuracy: 0.8030 - val_loss: 0.8727\n",
      "\n",
      " TRAIN: semg_net (Weighted)\n",
      "Epoch 1/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 28ms/step - accuracy: 0.5451 - loss: 1.6210 - val_accuracy: 0.7501 - val_loss: 0.9506\n",
      "Epoch 2/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.6810 - loss: 1.3597 - val_accuracy: 0.7476 - val_loss: 0.9148\n",
      "Epoch 3/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.6998 - loss: 1.3133 - val_accuracy: 0.7664 - val_loss: 0.8741\n",
      "Epoch 4/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.7141 - loss: 1.2881 - val_accuracy: 0.7342 - val_loss: 0.9419\n",
      "Epoch 5/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.7266 - loss: 1.2673 - val_accuracy: 0.7772 - val_loss: 0.8780\n",
      "Epoch 6/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.7334 - loss: 1.2501 - val_accuracy: 0.7658 - val_loss: 0.8783\n",
      "Epoch 7/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.7426 - loss: 1.2328 - val_accuracy: 0.7760 - val_loss: 0.8676\n",
      "Epoch 8/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.7497 - loss: 1.2202 - val_accuracy: 0.7892 - val_loss: 0.8544\n",
      "Epoch 9/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.7587 - loss: 1.2039 - val_accuracy: 0.7980 - val_loss: 0.8490\n",
      "Epoch 10/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.7653 - loss: 1.1899 - val_accuracy: 0.8052 - val_loss: 0.8373\n",
      "Epoch 11/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.7705 - loss: 1.1794 - val_accuracy: 0.7980 - val_loss: 0.8658\n",
      "Epoch 12/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.7777 - loss: 1.1640 - val_accuracy: 0.8023 - val_loss: 0.8609\n",
      "Epoch 13/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.7829 - loss: 1.1515 - val_accuracy: 0.8164 - val_loss: 0.8412\n",
      "Epoch 14/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.7897 - loss: 1.1392 - val_accuracy: 0.8074 - val_loss: 0.8444\n",
      "Epoch 15/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.7932 - loss: 1.1300 - val_accuracy: 0.8195 - val_loss: 0.8338\n",
      "Epoch 16/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.7968 - loss: 1.1190 - val_accuracy: 0.8216 - val_loss: 0.8331\n",
      "Epoch 17/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.7982 - loss: 1.1145 - val_accuracy: 0.8236 - val_loss: 0.8332\n",
      "Epoch 18/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.8010 - loss: 1.1112 - val_accuracy: 0.7839 - val_loss: 0.8920\n",
      "Epoch 19/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.7648 - loss: 1.1898 - val_accuracy: 0.7976 - val_loss: 0.8537\n",
      "Epoch 20/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7678 - loss: 1.1911 - val_accuracy: 0.7912 - val_loss: 0.8922\n",
      "Epoch 21/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.7686 - loss: 1.1939 - val_accuracy: 0.7872 - val_loss: 0.8749\n",
      "Epoch 22/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7707 - loss: 1.1902 - val_accuracy: 0.7807 - val_loss: 0.8946\n",
      "Epoch 23/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7721 - loss: 1.1887 - val_accuracy: 0.8008 - val_loss: 0.8774\n",
      "Epoch 24/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7745 - loss: 1.1845 - val_accuracy: 0.7993 - val_loss: 0.8686\n",
      "Epoch 25/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7767 - loss: 1.1795 - val_accuracy: 0.7823 - val_loss: 0.9027\n",
      "Epoch 26/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.7803 - loss: 1.1754 - val_accuracy: 0.8214 - val_loss: 0.8428\n",
      "Epoch 27/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7830 - loss: 1.1690 - val_accuracy: 0.8093 - val_loss: 0.8689\n",
      "Epoch 28/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7848 - loss: 1.1647 - val_accuracy: 0.7955 - val_loss: 0.8905\n",
      "Epoch 29/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7863 - loss: 1.1598 - val_accuracy: 0.8055 - val_loss: 0.8737\n",
      "Epoch 30/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7905 - loss: 1.1543 - val_accuracy: 0.8061 - val_loss: 0.8661\n",
      "Epoch 31/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7926 - loss: 1.1507 - val_accuracy: 0.8161 - val_loss: 0.8454\n",
      "Epoch 32/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7933 - loss: 1.1449 - val_accuracy: 0.8091 - val_loss: 0.8654\n",
      "Epoch 33/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7964 - loss: 1.1379 - val_accuracy: 0.8164 - val_loss: 0.8460\n",
      "Epoch 34/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7974 - loss: 1.1370 - val_accuracy: 0.8111 - val_loss: 0.8561\n",
      "Epoch 35/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.8015 - loss: 1.1313 - val_accuracy: 0.8326 - val_loss: 0.8227\n",
      "Epoch 36/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.8025 - loss: 1.1245 - val_accuracy: 0.8192 - val_loss: 0.8338\n",
      "Epoch 37/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.8033 - loss: 1.1216 - val_accuracy: 0.8148 - val_loss: 0.8433\n",
      "Epoch 38/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.8071 - loss: 1.1142 - val_accuracy: 0.8280 - val_loss: 0.8266\n",
      "Epoch 39/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.8091 - loss: 1.1084 - val_accuracy: 0.8247 - val_loss: 0.8270\n",
      "Epoch 40/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.8110 - loss: 1.1027 - val_accuracy: 0.8278 - val_loss: 0.8193\n",
      "Epoch 41/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.8134 - loss: 1.0984 - val_accuracy: 0.8272 - val_loss: 0.8180\n",
      "Epoch 42/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.8154 - loss: 1.0938 - val_accuracy: 0.8232 - val_loss: 0.8216\n",
      "Epoch 43/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.8170 - loss: 1.0878 - val_accuracy: 0.8252 - val_loss: 0.8271\n",
      "Epoch 44/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.8182 - loss: 1.0829 - val_accuracy: 0.8244 - val_loss: 0.8197\n",
      "Epoch 45/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.8204 - loss: 1.0788 - val_accuracy: 0.8272 - val_loss: 0.8228\n",
      "Epoch 46/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.8214 - loss: 1.0759 - val_accuracy: 0.8304 - val_loss: 0.8141\n",
      "Epoch 47/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.8227 - loss: 1.0720 - val_accuracy: 0.8286 - val_loss: 0.8161\n",
      "Epoch 48/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.8239 - loss: 1.0689 - val_accuracy: 0.8317 - val_loss: 0.8168\n",
      "Epoch 49/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.8254 - loss: 1.0666 - val_accuracy: 0.8342 - val_loss: 0.8141\n",
      "Epoch 50/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.8268 - loss: 1.0618 - val_accuracy: 0.8323 - val_loss: 0.8175\n",
      "Epoch 51/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.8272 - loss: 1.0605 - val_accuracy: 0.8333 - val_loss: 0.8162\n",
      "Epoch 52/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.8272 - loss: 1.0598 - val_accuracy: 0.8342 - val_loss: 0.8165\n",
      "Epoch 53/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.8278 - loss: 1.0589 - val_accuracy: 0.8345 - val_loss: 0.8168\n",
      "Epoch 54/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.8295 - loss: 1.0564 - val_accuracy: 0.8070 - val_loss: 0.8610\n",
      "Epoch 55/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7983 - loss: 1.1281 - val_accuracy: 0.8008 - val_loss: 0.8633\n",
      "Epoch 56/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7972 - loss: 1.1335 - val_accuracy: 0.7995 - val_loss: 0.8680\n",
      "Epoch 57/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7972 - loss: 1.1366 - val_accuracy: 0.7994 - val_loss: 0.8747\n",
      "Epoch 58/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7975 - loss: 1.1390 - val_accuracy: 0.7900 - val_loss: 0.8782\n",
      "Epoch 59/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.7967 - loss: 1.1415 - val_accuracy: 0.7808 - val_loss: 0.8954\n",
      "Epoch 60/60\n",
      "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.7976 - loss: 1.1420 - val_accuracy: 0.7872 - val_loss: 0.8937\n"
     ]
    }
   ],
   "source": [
    "# Execute main pipeline\n",
    "X_train, y_train_hot, X_val, y_val_hot, X_test, y_test, input_shape, n_classes, class_weights = main()\n",
    "\n",
    "# Train models\n",
    "path_inception = train_and_save(make_inception_se_tcn, \"inception_se\",\n",
    "                                X_train, y_train_hot, X_val, y_val_hot, input_shape, n_classes, class_weights)\n",
    "\n",
    "path_semgnet = train_and_save(make_semg_net, \"semg_net\",\n",
    "                              X_train, y_train_hot, X_val, y_val_hot, input_shape, n_classes, class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation-header",
   "metadata": {
    "id": "evaluation-header"
   },
   "source": [
    "## Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "evaluation",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "evaluation",
    "outputId": "0e5bb953-1bc2-4f61-d72c-3296e2bfbdad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " FINAL EVALUATION (2-Model Weighted)\n",
      "\n",
      "FINAL ACCURACY: 0.8441\n",
      "FINAL F1 SCORE: 0.8443\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n FINAL EVALUATION (2-Model Weighted)\\n\")\n",
    "\n",
    "# Load trained models\n",
    "m1 = make_inception_se_tcn(input_shape, n_classes)\n",
    "m1.load_weights(path_inception)\n",
    "\n",
    "m2 = make_semg_net(input_shape, n_classes)\n",
    "m2.load_weights(path_semgnet)\n",
    "\n",
    "# Make predictions\n",
    "p1 = m1.predict(X_test, batch_size=BATCH_SIZE, verbose=0)\n",
    "p2 = m2.predict(X_test, batch_size=BATCH_SIZE, verbose=0)\n",
    "\n",
    "# Ensemble predictions (simple average)\n",
    "ensemble_probs = (p1 + p2) / 2.0\n",
    "ensemble_preds = ensemble_probs.argmax(axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "acc = accuracy_score(y_test, ensemble_preds)\n",
    "f1 = f1_score(y_test, ensemble_preds, average='macro')\n",
    "\n",
    "print(f\"FINAL ACCURACY: {acc:.4f}\")\n",
    "print(f\"FINAL F1 SCORE: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
