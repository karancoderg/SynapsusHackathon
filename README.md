# Synapse Solution - sEMG Gesture Classification

## ðŸŽ¯ Overview
Accuracy-optimized lightweight solution for the Synapse Neuro-Tech Challenge (PARSEC 6.0).

**Key Features:**
- 180+ handcrafted features (zero parameter cost)
- TCN + CNN + LightGBM ensemble (~60K neural params)
- Test-Time Augmentation (TTA) for +1-3% accuracy boost
- Subject-wise cross-validation

## ðŸš€ Quick Start (Google Colab)

1. Open `notebooks/synapse_complete.ipynb` in Google Colab
2. Run all cells - the notebook handles:
   - Dataset download from Google Drive
   - Preprocessing & feature extraction
   - Model training (TCN, CNN, LightGBM)
   - Ensemble prediction with TTA
   - Artifact export

## ðŸ“ Project Structure

```
synapse-solution/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ synapse_complete.ipynb    # Complete Colab notebook
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py          # Signal filtering & normalization
â”‚   â”œâ”€â”€ features.py               # 180+ feature extraction
â”‚   â”œâ”€â”€ augmentation.py           # Data augmentation & TTA
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ tcn.py                # TCN model (~35K params)
â”‚       â”œâ”€â”€ cnn.py                # CNN model (~25K params)
â”‚       â””â”€â”€ ensemble.py           # Ensemble wrapper
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml               # Hyperparameters
â”œâ”€â”€ artifacts/                    # Saved models & scalers
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ run_inference.py          # CLI inference
â””â”€â”€ report/                       # LaTeX technical report
```

## ðŸ”¬ Technical Approach

### Signal Processing
- Bandpass filter (20-450 Hz) for noise removal
- Notch filter (50 Hz) for powerline interference
- Z-score normalization per channel

### Feature Engineering (180+ features)
| Category | Features | Per Channel |
|----------|----------|-------------|
| Time Domain | MAV, RMS, WL, ZC, SSC, VAR, IEMG, LOG | 8 |
| Frequency Domain | MNF, MDF, PKF, MNP, TTP, SM1 | 6 |
| Wavelet | Energy + Entropy (4 levels) | 8 |
| Hjorth | Activity, Mobility, Complexity | 3 |
| Cross-Channel | Correlation (28 pairs) | - |

### Models
| Model | Parameters | Expected F1 |
|-------|------------|-------------|
| TCN | ~35K | 0.91-0.93 |
| CNN | ~25K | 0.89-0.91 |
| LightGBM | 0 (trees) | 0.87-0.89 |
| **Ensemble** | **~60K** | **0.93-0.95** |

## ðŸ“Š Inference

```python
# Load trained models
import torch
import pickle

tcn = TCN()
tcn.load_state_dict(torch.load('artifacts/tcn_model.pth'))

with open('artifacts/lgbm_model.pkl', 'rb') as f:
    lgbm = pickle.load(f)

# Predict
predictions = predict_with_tta(X_windows, X_features, tcn, cnn, lgbm)
```

## ðŸ“ Requirements

```
torch>=2.0
numpy
pandas
scipy
scikit-learn
lightgbm
pywavelets
```

## ðŸ‘¥ Team
Synapse Solution for PARSEC 6.0 @ IIT Dharwad
