# ğŸš€ Inference Guide â€” 2-Model sEMG Ensemble

This document explains **how to correctly run inference** using the trained **Inception-SE + sEMG-Net ensemble** for both **internal validation** and **external / production data**.

The inference pipeline strictly **matches training preprocessing and model architecture** to ensure reproducibility.

---

## ğŸ“Œ Available Inference Scripts

### 1ï¸âƒ£ `test_half_session3.ipynb` â€” Internal Validation

**Evaluates on**
- 50% of **Session 3** (held-out split from training)

**Purpose**
- Sanity check after training  
- Regression testing  
- Baseline comparison

**Expected Accuracy**
- ~85%

```bash
jupyter nbconvert --to script test_half_session3.ipynb.
python test_half_session3.py
```

---

### 2ï¸âƒ£ `run_inference_full.py` â€” Production / External Data (Recommended)

**Evaluates on**
- Any dataset you provide

**Purpose**
- New data
- Competition test sets
- Deployment / batch inference

**Expected Accuracy**
- ~85% on similar data

```bash
python run_inference_full.py
```

---

## ğŸ” Key Differences

| Script | Test Data | Use Case |
|------|----------|---------|
| `run_inference.ipynb` | Session3 (50%) | Internal validation |
| `run_inference_full.py` | Custom directory | External / production inference |

---

## ğŸ“‚ Required Data Layout

Your inference data **must follow the same structure as training data**.

```
your_data/
â”œâ”€â”€ Session1/
â”‚   â”œâ”€â”€ gesture0/
â”‚   â”‚   â”œâ”€â”€ sample_01.csv
â”‚   â”‚   â””â”€â”€ sample_02.csv
â”‚   â”œâ”€â”€ gesture1/
â”‚   â”œâ”€â”€ gesture2/
â”‚   â”œâ”€â”€ gesture3/
â”‚   â””â”€â”€ gesture4/
â”œâ”€â”€ Session2/
â””â”€â”€ Session3/
```

### CSV Requirements
- **8 columns** = 8 sEMG channels
- **Sampling rate**: 512 Hz
- No missing values
- Filenames must include `gestureX` or be inside `gestureX/`

---

## âš™ï¸ Running Inference on New Data

### Step 1: Set Data Directory

Edit `run_inference_full.py`:

```python
DATA_DIR = 'path/to/your/new/data'
```

### Step 2: Run Inference

```bash
python run_inference_full.py
```

---

## ğŸ“ˆ Output Files

### `test_half_session3.ipynb`
- Confusion matrix image
- Console metrics (Accuracy, F1)

### `run_inference_full.py`
```
artifacts_final/
â”œâ”€â”€ ensemble_all_data_matrix.png
â”œâ”€â”€ ensemble_all_data_results.txt
```

---

## âš ï¸ Data Compatibility Rules

For reliable performance:

1. Same **gesture set** (classes 0â€“4)
2. Same **sampling rate** (512 Hz)
3. Similar **electrode placement**
4. Similar **recording conditions**

---

## ğŸ“Š Expected Performance

| Scenario | Accuracy |
|-------|---------|
| Same subjects, same session | 85â€“90% |
| Same subjects, different day | 80â€“85% |
| New subjects | 70â€“80% |
| New setup / electrodes | 60â€“75% |

Large drops indicate **domain shift**, not model failure.

---

## ğŸ› ï¸ Troubleshooting

### âŒ Model not found
```bash
ls artifacts_final/*.keras
```

Expected:
- `best_inception_se.keras`
- `best_semg_net.keras`

---

### âŒ Shape mismatch
- CSV must have **exactly 8 columns**
- Sampling rate must be **512 Hz**

```bash
head -5 your_data/Session1/gesture0/sample_01.csv
```

---

### âŒ Low accuracy on new data
Likely causes:
- Different subjects
- Different electrode placement
- Different recording protocol

Recommended actions:
- Fine-tune on small labeled subset
- Apply transfer learning
- Collect calibration data

---

## ğŸ” Batch Inference (Advanced)

```python
datasets = [
    'dataset_A',
    'dataset_B',
    'dataset_C'
]

for ds in datasets:
    DATA_DIR = ds
    # run inference
    # save results per dataset
```

---

## âœ… Summary

- Use **`run_inference.ipynb`** for internal validation
- Use **`run_inference_full.py`** for external / production data
- Always match training preprocessing
- Expect degradation under domain shift

This inference setup is **reproducible, leakage-safe, and production-ready**.
